{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SPARQL PP into N3 PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.sparql import parser\n",
    "from convert_pp_sparql_n3 import To_N3_Visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert single query\n",
    "\n",
    "query = \"SELECT ?x WHERE { ?x (:p1/:p2)* ?z ; !(:p3|:p4|:p5) ?a }\"\n",
    "query = \"PREFIX : <http://example.org/gmark/> \" + \\\n",
    "    \"SELECT * WHERE { ?x0 ((^:p1/:p2*)?/:p3)+ ?x3 } \"\n",
    "    # \"SELECT * WHERE { ?x0 !(:p1|^:p2|:p3) ?x3 }\"\n",
    "\n",
    "query = parser.parseQuery(query)\n",
    "query = query[1]\n",
    "\n",
    "print(To_N3_Visitor().convert(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-0.sparql\n",
      "query-1.sparql\n",
      "query-10.sparql\n",
      "query-11.sparql\n",
      "query-12.sparql\n",
      "query-13.sparql\n",
      "query-14.sparql\n",
      "query-15.sparql\n",
      "query-16.sparql\n",
      "query-17.sparql\n",
      "query-18.sparql\n",
      "query-19.sparql\n",
      "query-2.sparql\n",
      "query-20.sparql\n",
      "query-21.sparql\n",
      "query-22.sparql\n",
      "query-23.sparql\n",
      "query-24.sparql\n",
      "query-25.sparql\n",
      "query-26.sparql\n",
      "query-27.sparql\n",
      "query-28.sparql\n",
      "query-29.sparql\n",
      "query-3.sparql\n",
      "query-30.sparql\n",
      "query-31.sparql\n",
      "query-32.sparql\n",
      "query-33.sparql\n",
      "query-34.sparql\n",
      "query-35.sparql\n",
      "query-36.sparql\n",
      "query-37.sparql\n",
      "query-38.sparql\n",
      "query-39.sparql\n",
      "query-4.sparql\n",
      "query-40.sparql\n",
      "query-41.sparql\n",
      "query-42.sparql\n",
      "query-43.sparql\n",
      "query-44.sparql\n",
      "query-45.sparql\n",
      "query-46.sparql\n",
      "query-47.sparql\n",
      "query-48.sparql\n",
      "query-49.sparql\n",
      "query-5.sparql\n",
      "query-6.sparql\n",
      "query-7.sparql\n",
      "query-8.sparql\n",
      "query-9.sparql\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert query folder\n",
    "\n",
    "import os\n",
    "\n",
    "visitor = To_N3_Visitor()\n",
    "\n",
    "path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/gmark_50_new/mix\"\n",
    "files = list(os.listdir(path))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    print(file)\n",
    "    with open(os.path.join(path, file), 'r') as fh:\n",
    "        query = fh.read()\n",
    "        query = parser.parseQuery(query)\n",
    "        query = query[1]\n",
    "        \n",
    "        conv = visitor.convert(query)\n",
    "        conv = \"@prefix : <http://example.org/gmark/> .\\n\\n\" + conv\n",
    "        # print(conv)\n",
    "        \n",
    "        n3_file = file[0:file.index(\".\")] + \".n3\"\n",
    "        with open(os.path.join(path, \"n3\", n3_file), 'w') as fh2:\n",
    "            fh2.write(conv)\n",
    "            \n",
    "        # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SPARQL PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resCSV2NT import convert as csv2nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_sparql(query_file, data_file, result_file):\n",
    "    process = subprocess.Popen(['java', '-jar', \"../test/run/sparql.jar\", \"-n3\", data_file, \"-query\", query_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    print(out)\n",
    "    print(error)\n",
    "    \n",
    "    with open(result_file, 'w') as fh:\n",
    "        fh.write(out.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/gmark_50_new/mix\"\n",
    "files = list(os.listdir(path))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    # print(file)\n",
    "    \n",
    "    name = file[:file.index(\".\")]\n",
    "    query_file = os.path.join(path, file)\n",
    "    data_file = os.path.join(path, \"data.n3\")\n",
    "    result_file_csv = os.path.join(path, \"results\", f\"{name}.csv\")\n",
    "    result_file_nt = os.path.join(path, \"results\", f\"{name}.nt\")\n",
    "    \n",
    "    exec_sparql(query_file, data_file, result_file_csv)\n",
    "    \n",
    "    csv2nt(file=result_file_csv , ordered=False, out=result_file_nt)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run N3 PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNSave(cmd, path, get_times=True):\n",
    "    # result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    out = out.rstrip()\n",
    "    # print(\"out:\", out)\n",
    "    # print(\"error:\", error)\n",
    "        \n",
    "    with open(path, 'w') as fh:\n",
    "        fh.write(out)\n",
    "    \n",
    "    if get_times:\n",
    "        netw_time = int(re.search(\"networking \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n",
    "        reas_time = int(re.search(\"reasoning \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n",
    "        return netw_time, reas_time\n",
    "\n",
    "def record(times_file, query, data, type, phase, netw_time, reas_time):\n",
    "    times_file.write(f\"{query},{data},{type},{phase},{netw_time},{reas_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground & normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/other_systems/gmark-dominik/50/\"\n",
    "path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/gmark_50_new/mix/\"\n",
    "for file in os.listdir(path):    \n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    \n",
    "    file = file[:file.index(\".\")] + \".n3\"\n",
    "    or_file = os.path.join(path, \"n3\", file)\n",
    "    norm_file = os.path.join(path, \"n3\", \"normalized\", file)\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    # ground\n",
    "    runNSave([\"eye\", \"--quiet\", or_file, \"--no-qvars\", \"--nope\", \"--pass-all\"], norm_file, get_times=False)\n",
    "    \n",
    "    # normalize\n",
    "    runNSave([\"eye\", \"--quiet\", norm_file, \"aux_list.n3\", \"--query\", \"list-predicate.n3\", \"--quantify\", \"http://www.w3.org/2000/10/swap/var#\", \"--nope\"], norm_file, get_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/other_systems/gmark-dominik/50/\"\n",
    "path = \"/Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/gmark_50_new/mix/\"\n",
    "\n",
    "times_file = open(os.path.join(path, \"n3\", \"results\", \"times.csv\"), 'w')\n",
    "times_file.write(\"query,data,type,phase,netw_time,reas_time\\n\")\n",
    "\n",
    "files = list(os.listdir(os.path.join(path, \"n3\", \"normalized\")))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.startswith(\"query\") and not file.endswith(\".n3\"):\n",
    "        continue\n",
    "    \n",
    "    name = file[:file.index(\".\")]\n",
    "    norm_file = os.path.join(path, \"n3\", \"normalized\", file)\n",
    "    data_file = \"data.n3\"\n",
    "    data_path = os.path.join(path, data_file)\n",
    "    dir_res_file = os.path.join(path, \"n3\", \"results\", \"direct\", file)\n",
    "    bwd_res_file = os.path.join(path, \"n3\", \"results\", \"bwd\", file)\n",
    "    fwd_res_file = os.path.join(path, \"n3\", \"results\", \"fwd\", file)\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    # - direct \n",
    "    netw_time, reas_time = runNSave([\"eye\", data_path, \"property-paths-direct.n3\", \"--query\", norm_file, \"--nope\"], dir_res_file)\n",
    "    record(times_file, file, data_file, 'direct', 'n/a', netw_time, reas_time)\n",
    "    \n",
    "    # - backward\n",
    "    tmp_file = os.path.join(path, \"n3\", \"gen\", f\"{name}_bwd.n3\")\n",
    "    netw_time1, reas_time1 = runNSave([\"eye\", norm_file, \"rule-creation.n3\", \"--query\", \"rule-creation-backwards.n3\", \"--nope\"], tmp_file)\n",
    "    record(times_file, file, data_file, 'bwd', 'create', netw_time1, reas_time1)\n",
    "    netw_time2, reas_time2 = runNSave([\"eye\", data_path, tmp_file, \"--query\", norm_file, \"--nope\"], bwd_res_file)\n",
    "    record(times_file, file, data_file, 'bwd', 'run', netw_time2, reas_time2)\n",
    "    record(times_file, file, data_file, 'bwd', 'total', netw_time1+netw_time2, reas_time1+reas_time2)\n",
    "        \n",
    "    # - forward\n",
    "    tmp_file = os.path.join(path, \"n3\", \"gen\", f\"{name}_fwd.n3\")\n",
    "    netw_time1, reas_time1 = runNSave([\"eye\", norm_file, \"rule-creation.n3\", \"--query\", \"rule-creation.n3\", \"--nope\"], tmp_file)\n",
    "    record(times_file, file, data_file, 'fwd', 'create', netw_time1, reas_time1)\n",
    "    netw_time2, reas_time2 = runNSave([\"eye\", data_path, tmp_file, \"--query\", norm_file, \"--nope\"], fwd_res_file)\n",
    "    record(times_file, file, data_file, 'fwd', 'run', netw_time2, reas_time2)\n",
    "    record(times_file, file, data_file, 'fwd', 'total', netw_time1+netw_time2, reas_time1+reas_time2)\n",
    "    \n",
    "    times_file.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
