{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/b6/7128wh613rqcbppftg_0hb2h0000gn/T/ipykernel_43504/3417448837.py:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  netw_time = int(re.search(\"networking \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n",
      "/var/folders/b6/7128wh613rqcbppftg_0hb2h0000gn/T/ipykernel_43504/3417448837.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  reas_time = int(re.search(\"reasoning \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n"
     ]
    }
   ],
   "source": [
    "def run(cmd):    \n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    \n",
    "    if error.strip() != \"\":\n",
    "        print(error)\n",
    "\n",
    "    print(out)\n",
    "\n",
    "def runNSave(cmd, path, get_times=True):\n",
    "    # result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    out = out.rstrip()\n",
    "    # print(\"out:\", out)\n",
    "    print(\"error:\", error)\n",
    "        \n",
    "    with open(path, 'w') as fh:\n",
    "        fh.write(out)\n",
    "    \n",
    "    if \"** ERROR **\" in error:\n",
    "        print(\"ERROR:\", error)\n",
    "    \n",
    "    elif get_times:\n",
    "        netw_time = int(re.search(\"networking \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n",
    "        reas_time = int(re.search(\"reasoning \\d+ \\[msec cputime\\] (\\d+) \\[msec walltime\\]\", error).group(1))\n",
    "        return netw_time, reas_time\n",
    "\n",
    "def record(times_file, query, data, type, phase, netw_time, reas_time):\n",
    "    times_file.write(f\"{query},{data},{type},{phase},{netw_time},{reas_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SPARQL PP into N3 PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE for now run with Python 3.11.5 (manually fixed issue with NegatedPropertySet & reverse paths)\n",
    "\n",
    "from rdflib.plugins.sparql import parser\n",
    "from convert_pp_sparql_n3 import To_N3_Visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if someone else is running this notebook:\n",
    "\n",
    "# @rdflib.plugins.sparql.parserutils.py#279\n",
    "# add:\n",
    "# elif isinstance(t,CompValue) or isinstance(t,URIRef):\n",
    "#     res['part'] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ ?x0 ((( '^' :p1) '/' :p1 '/' ( '^' :p1) '/' :p1) '*' ) ?x1 . ?x1 ((( '^' :p1) '/' :p1 '/' ( '^' :p1)) '|' (( '^' :p1) '/' :p1 '/' ( '^' :p1))) ?x2 . ?x2 ((:p1 '/' ( '^' :p1)) '+' ) ?x3 }\n",
      " => { _:x :result ( ('x2' ?x2) ('x1' ?x1) ('x3' ?x3) ('x0' ?x0) ) } .\n"
     ]
    }
   ],
   "source": [
    "# convert single query\n",
    "\n",
    "# query = \"SELECT ?x WHERE { ?x (:p1/:p2)* ?z ; !(:p3|:p4|:p5) ?a }\"\n",
    "# query = \"PREFIX : <http://example.org/gmark/> \" + \\\n",
    "#     \"SELECT * WHERE { ?x0 !(^:p1|:p2) ?x3 } \"\n",
    "#     # \"SELECT * WHERE { ?x0 ((^:p1/:p2*)?/:p3)+ ?x3 } \"\n",
    "#     # \"SELECT * WHERE { ?x0 !(:p1|^:p2|:p3) ?x3 }\"\n",
    "query = \"\"\"PREFIX : <http://example.org/gmark/> \n",
    "SELECT DISTINCT ?x2 ?x1 ?x3 ?x0 \n",
    "WHERE {  {  ?x0 (((^:p1/:p1/^:p1/:p1)))* ?x1 . ?x1 ((^:p1/:p1/^:p1)|(^:p1/:p1/^:p1)) ?x2 . ?x2 (((:p1/^:p1)))+ ?x3 . } }\n",
    "\"\"\"\n",
    "\n",
    "query = parser.parseQuery(query)\n",
    "query = query[1]\n",
    "\n",
    "print(To_N3_Visitor().convert(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert query folder\n",
    "\n",
    "import os\n",
    "\n",
    "visitor = To_N3_Visitor()\n",
    "\n",
    "path = \"../../gmark_50_new/mix\"\n",
    "files = list(os.listdir(path))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    print(file)\n",
    "    with open(os.path.join(path, file), 'r') as fh:\n",
    "        query = fh.read()\n",
    "        query = parser.parseQuery(query)\n",
    "        query = query[1]\n",
    "        \n",
    "        conv = visitor.convert(query)\n",
    "        conv = \"@prefix : <http://example.org/gmark/> .\\n\\n\" + conv\n",
    "        # print(conv)\n",
    "        \n",
    "        n3_file = file[0:file.index(\".\")] + \".n3\"\n",
    "        with open(os.path.join(path, \"n3\", n3_file), 'w') as fh2:\n",
    "            fh2.write(conv)\n",
    "        \n",
    "        # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SPARQL PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resCSV2N3 import convert as csv2n3\n",
    "# from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_sparql(query_file, data_file, result_file):\n",
    "    process = subprocess.Popen(['java', '-jar', \"../test/run/sparql.jar\", \"-n3\", data_file, \"-query\", query_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    if error.strip() != \"\":\n",
    "        print(error)\n",
    "    else:   \n",
    "        with open(result_file, 'w') as fh:\n",
    "            fh.write(out.strip())\n",
    "            \n",
    "    # g = Graph(); g.parse(data_file)\n",
    "    # g.query(open(query_file, 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run single query\n",
    "\n",
    "# path = \"../../gmark_50_new/mix\"\n",
    "path = \"test\"\n",
    "file = \"test3.sparql\"\n",
    "name = file[:file.index(\".\")]\n",
    "query_file = os.path.join(path, file)\n",
    "data_file = os.path.join(path, \"data3.n3\")\n",
    "result_file_csv = os.path.join(path, f\"{name}_results_sparql.csv\")\n",
    "\n",
    "exec_sparql(query_file, data_file, result_file_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run query folder\n",
    "\n",
    "path = \"../../gmark_50_new/mix\"\n",
    "files = list(os.listdir(path))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    print(file)\n",
    "    \n",
    "    name = file[:file.index(\".\")]\n",
    "    query_file = os.path.join(path, file)\n",
    "    data_file = os.path.join(path, \"data.n3\")\n",
    "    result_file_csv = os.path.join(path, \"results\", f\"{name}.csv\")\n",
    "    result_file_n3 = os.path.join(path, \"results\", f\"{name}.n3\")\n",
    "    \n",
    "    exec_sparql(query_file, data_file, result_file_csv)\n",
    "    \n",
    "    csv2n3(file=result_file_csv , ordered=False, out=result_file_n3)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run N3 PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground & normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize single file\n",
    "\n",
    "path = \"test\"\n",
    "or_file = os.path.join(path, \"evil pp 1.n3\")\n",
    "norm_file = os.path.join(path, \"evil pp 12.n3\")\n",
    "\n",
    "# ground\n",
    "runNSave([\"eye\", \"--quiet\", or_file, \"--no-qvars\", \"--nope\", \"--pass-all\"], norm_file, get_times=False)\n",
    "    \n",
    "# normalize\n",
    "runNSave([\"eye\", \"--quiet\", norm_file, \"aux_list.n3\", \"--query\", \"list-predicate.n3\", \"--quantify\", \"http://www.w3.org/2000/10/swap/var#\", \"--nope\"], norm_file, get_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize entire folder\n",
    "\n",
    "path = \"../../gmark_50_new/mix\"\n",
    "for file in os.listdir(path):    \n",
    "    if not file.endswith(\".sparql\"):\n",
    "        continue\n",
    "    \n",
    "    file = file[:file.index(\".\")] + \".n3\"\n",
    "    or_file = os.path.join(path, \"n3\", file)\n",
    "    norm_file = os.path.join(path, \"n3\", \"normalized\", file)\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    # ground\n",
    "    runNSave([\"eye\", \"--quiet\", or_file, \"--no-qvars\", \"--nope\", \"--pass-all\"], norm_file, get_times=False)\n",
    "    \n",
    "    # normalize\n",
    "    runNSave([\"eye\", \"--quiet\", norm_file, \"aux_list.n3\", \"--query\", \"list-predicate.n3\", \"--quantify\", \"http://www.w3.org/2000/10/swap/var#\", \"--nope\"], norm_file, get_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: eye --quiet test/data-or.n3 property-paths-direct.n3 --query test/evil_pp_1.n3 --nope\n",
      "EYE v11.19.7 (2025-06-01)\n",
      "SWI-Prolog version 9.2.7\n",
      "starting 26 [msec cputime] 30 [msec walltime]\n",
      "GET file:///Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/SPIN-to-N3/property-paths/test/data-or.n3 SC=55\n",
      "GET file:///Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/SPIN-to-N3/property-paths/property-paths-direct.n3 SC=17\n",
      "GET file:///Users/wvw/git/n3/sparql2n3/SPARQL-to-N3/SPIN-to-N3/property-paths/test/evil_pp_1.n3 SC=1\n",
      "networking 8 [msec cputime] 10 [msec walltime]\n",
      "reasoning 5017 [msec cputime] 5278 [msec walltime]\n",
      "2025-06-05T13:12:01.930Z in=73 out=61 ent=61 step=142946 brake=2 inf=79990783 sec=5.051 inf/sec=15836623\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run single rule\n",
    "\n",
    "path = \"test\"\n",
    "norm_file = os.path.join(path, \"evil_pp_1.n3\")\n",
    "data_path = os.path.join(path, \"data-or.n3\")\n",
    "# rules_file = os.path.join(path, \"test3_rule_creation.n3\")\n",
    "res_file = os.path.join(path, \"evil_pp_1-results.n3\")\n",
    "\n",
    "runNSave([\"eye\", data_path, \"property-paths-direct.n3\", \"--query\", norm_file, \"--nope\"], res_file, get_times=False)\n",
    "\n",
    "# netw_time, reas_time = runNSave([\"eye\", norm_file, \"rule-creation.n3\", \"--query\", \"rule-creation.n3\", \"--nope\"], rules_file)\n",
    "# netw_time2, reas_time2 = runNSave([\"eye\", data_path, rules_file, \"--query\", norm_file, \"--nope\"], res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run folder\n",
    "\n",
    "path = \"../../gmark_50_new/mix\"\n",
    "\n",
    "times_file = open(os.path.join(path, \"n3\", \"results\", \"times.csv\"), 'w')\n",
    "times_file.write(\"query,data,type,phase,netw_time,reas_time\\n\")\n",
    "\n",
    "files = list(os.listdir(os.path.join(path, \"n3\", \"normalized\")))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.startswith(\"query\") and not file.endswith(\".n3\"):\n",
    "        continue\n",
    "    \n",
    "    name = file[:file.index(\".\")]\n",
    "    norm_file = os.path.join(path, \"n3\", \"normalized\", file)\n",
    "    data_file = \"data.n3\"\n",
    "    data_path = os.path.join(path, data_file)\n",
    "    dir_res_file = os.path.join(path, \"n3\", \"results\", \"direct\", file)\n",
    "    bwd_res_file = os.path.join(path, \"n3\", \"results\", \"bwd\", file)\n",
    "    fwd_res_file = os.path.join(path, \"n3\", \"results\", \"fwd\", file)\n",
    "    \n",
    "    print(norm_file)\n",
    "    \n",
    "    # - direct \n",
    "    netw_time, reas_time = runNSave([\"eye\", data_path, \"property-paths-direct.n3\", \"--query\", norm_file, \"--nope\"], dir_res_file)\n",
    "    record(times_file, file, data_file, 'direct', 'n/a', netw_time, reas_time)\n",
    "    \n",
    "    # - backward\n",
    "    tmp_file = os.path.join(path, \"n3\", \"gen\", f\"{name}_bwd.n3\")\n",
    "    netw_time1, reas_time1 = runNSave([\"eye\", norm_file, \"rule-creation.n3\", \"--query\", \"rule-creation-backwards.n3\", \"--nope\"], tmp_file)\n",
    "    record(times_file, file, data_file, 'bwd', 'create', netw_time1, reas_time1)\n",
    "    netw_time2, reas_time2 = runNSave([\"eye\", data_path, tmp_file, \"--query\", norm_file, \"--nope\"], bwd_res_file)\n",
    "    record(times_file, file, data_file, 'bwd', 'run', netw_time2, reas_time2)\n",
    "    record(times_file, file, data_file, 'bwd', 'total', netw_time1+netw_time2, reas_time1+reas_time2)\n",
    "        \n",
    "    # - forward\n",
    "    tmp_file = os.path.join(path, \"n3\", \"gen\", f\"{name}_fwd.n3\")\n",
    "    netw_time1, reas_time1 = runNSave([\"eye\", norm_file, \"rule-creation.n3\", \"--query\", \"rule-creation.n3\", \"--nope\"], tmp_file)\n",
    "    record(times_file, file, data_file, 'fwd', 'create', netw_time1, reas_time1)\n",
    "    netw_time2, reas_time2 = runNSave([\"eye\", data_path, tmp_file, \"--query\", norm_file, \"--nope\"], fwd_res_file)\n",
    "    record(times_file, file, data_file, 'fwd', 'run', netw_time2, reas_time2)\n",
    "    record(times_file, file, data_file, 'fwd', 'total', netw_time1+netw_time2, reas_time1+reas_time2)\n",
    "    \n",
    "    times_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SparqLog PP on Nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mError:\u001b[0m expected `.`\n",
      "   \u001b[38;5;246m╭\u001b[0m\u001b[38;5;246m─\u001b[0m\u001b[38;5;246m[\u001b[0mtest/misc/test3_sparqlog.nmo:9:8\u001b[38;5;246m]\u001b[0m\n",
      "   \u001b[38;5;246m│\u001b[0m\n",
      " \u001b[38;5;246m9 │\u001b[0m \u001b[38;5;249m@\u001b[0m\u001b[38;5;249mo\u001b[0m\u001b[38;5;249mu\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249mp\u001b[0m\u001b[38;5;249mu\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249m(\u001b[0m\u001b[38;5;249m\"\u001b[0m\u001b[38;5;249ma\u001b[0m\u001b[38;5;249mn\u001b[0m\u001b[38;5;249ms\u001b[0m\u001b[38;5;249m1\u001b[0m\u001b[38;5;249m\"\u001b[0m\u001b[38;5;249m)\u001b[0m\u001b[38;5;249m.\u001b[0m\n",
      " \u001b[38;5;240m  │\u001b[0m        \u001b[31m│\u001b[0m \n",
      " \u001b[38;5;240m  │\u001b[0m        \u001b[31m╰\u001b[0m\u001b[31m─\u001b[0m expected `.`\n",
      "\u001b[38;5;246m───╯\u001b[0m\n",
      "\u001b[90m[\u001b[0m2025-06-04T17:49:27Z \u001b[1m\u001b[31mERROR\u001b[0m nmo\u001b[90m]\u001b[0m \u001b[1;31merror:\u001b[0m unable to parse program `test/misc/test3_sparqlog.nmo`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"test\"\n",
    "in_path = os.path.join(path, \"misc/test3.sparql\")\n",
    "out_path = os.path.join(path, \"misc/test3_sparqlog.nmo\")\n",
    "\n",
    "run([\"java\", \"-jar\", \"sparql2sparqlog.jar\", in_path, out_path]) # translate\n",
    "run([\"/opt/nemo-0.6.0/nmo\", out_path, \"--export-dir\", \"results\", \"--overwrite-results\"]) # run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run N3 PP on Nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test\"\n",
    "# substitute for rule file without collections\n",
    "in_path = os.path.join(path, \"data.n3\") \n",
    "out_path = os.path.join(path, \"data.nmo\")\n",
    "\n",
    "run([\"java\", \"-jar\", \"n32nmo.jar\", in_path, out_path]) # translate\n",
    "# run([\"/opt/nemo-0.6.0/nmo\", out_path, \"--export-dir\", \"results\", \"--overwrite-results\"]) # run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(file1, file2):\n",
    "    process = subprocess.Popen(['java', '-jar', \"compare_res.jar\", file1, file2], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, error = [ b.decode('UTF-8') for b in process.communicate() ]\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"../../gmark_50_new/mix/results\"\n",
    "path2 = \"../../gmark_50_new/mix/n3/results/fwd\"\n",
    "files = list(os.listdir(path1))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if not file.endswith(\".n3\"):\n",
    "        continue\n",
    "    file1 = os.path.join(path1, file)\n",
    "    file2 = os.path.join(path2, file)\n",
    "    if not os.path.isfile(file2):\n",
    "        print(\"cannot find file2\")\n",
    "    else:\n",
    "        print(file)\n",
    "        compare_results(file1, file2)\n",
    "        print()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
